beautifulsoup4==4.12.3
lxml==5.3.0
requests==2.32.3

rank-bm25==0.2.2

faiss-cpu==1.8.0.post1      # if on Apple Silicon: faiss-cpu; on CUDA boxes you can swap for faiss-gpu
sentence-transformers==3.0.1

transformers==4.44.2
torch>=2.1.0                 # CPU is fine; GPU speeds up embedding/inference
accelerate==0.34.2

tqdm==4.66.4
numpy==1.26.4
